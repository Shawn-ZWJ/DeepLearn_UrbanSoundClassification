{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from models import *\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training data and extracting features\n",
    "X_data, Y_data = data_loader('C:\\\\Users\\\\Nildip.mukherjee\\\\AnacondaProjects\\\\Others\\\\USC\\\\UrbanSound\\\\data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding the sound clipping vectors\n",
    "X_data, max_lenX = padder(X_data)\n",
    "\n",
    "# extracting concatenated features\n",
    "X_train_concat = feat_extract_concat(X_data)\n",
    "max_lenX = max([len(i) for i in X_train_concat])\n",
    "\n",
    "# extracting seperated features\n",
    "X_stft,X_mfccs,X_chroma,X_mel,X_contrast,X_tonnetz = feat_extract_sep(X_data)\n",
    "input_shape_dict = {}\n",
    "for i in [(X_stft,'stft'),(X_mfccs,'mfccs'),(X_chroma,'chroma'),(X_mel,'mel'),(X_contrast,'contrast'),(X_tonnetz,'tonnetz')]:\n",
    "    input_shape_dict['len_{0}'.format(i[1])] = max([len(j) for j in i[0]])\n",
    "    \n",
    "# labelencoding train classes\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(Y_data)\n",
    "Y_data = np.array(le.transform(Y_data))\n",
    "\n",
    "# one hot encoding train classes\n",
    "Y_train = np_utils.to_categorical(Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in [X_stft,X_mfccs,X_chroma,X_mel,X_contrast,X_tonnetz]:\n",
    "    plt.figure(figsize= (17, 10))\n",
    "    for i in set(Y_data):\n",
    "        idx = ((np.where(np.array(Y_data)==i)))[0]\n",
    "        x_idx = np.array([k[j] for j in idx])\n",
    "        x_idx = pd.Series(x_idx).rolling(int(len(list(x_idx))/3)).mean()\n",
    "        plt.legend()\n",
    "        plt.plot(x_idx, label = i)  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping to required dimensions\n",
    "X_train_concat = np.expand_dims(np.array(X_train_concat), axis=2)\n",
    "\n",
    "X_stft = np.expand_dims(np.array(X_stft), axis=2)\n",
    "X_mfccs = np.expand_dims(np.array(X_mfccs), axis=2)\n",
    "X_chroma = np.expand_dims(np.array(X_chroma), axis=2)\n",
    "X_mel = np.expand_dims(np.array(X_mel), axis=2)\n",
    "X_contrast = np.expand_dims(np.array(X_contrast), axis=2)\n",
    "X_tonnetz = np.expand_dims(np.array(X_tonnetz), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into train-test (80-20)\n",
    "X_train_concat,X_test_concat,X_stft,X_stft_test,X_mfccs,X_mfccs_test,X_chroma,X_chroma_test,X_mel,X_mel_test,X_contrast,X_contrast_test,X_tonnetz,X_tonnetz_test,Y_train,Y_test = train_test_split(X_train_concat,X_stft,X_mfccs,X_chroma,X_mel,X_contrast,X_tonnetz,Y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = concat_1d_CNN(10,max_lenX)\n",
    "model.summary()\n",
    "# print model structure to png file\n",
    "plot_model(model, to_file='model_concat_1Dcnn.png', show_shapes = True)\n",
    "# complile the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# Fit the model\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience=2)\n",
    "model.fit(X_train_concat, Y_train, validation_data = (X_test_concat, Y_test), epochs=200, batch_size=256, \n",
    "          shuffle=True, callbacks=[early_stopping])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test_concat, Y_test, verbose=0)\n",
    "print(\"Model Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sep_1d_CNN(10,input_shape_dict)\n",
    "model.summary()\n",
    "# print model structure to png file\n",
    "plot_model(model, to_file='model_sep_1Dcnn.png', show_shapes = True)\n",
    "# complile the model\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# Fit the model\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience=2)\n",
    "model.fit([X_stft,X_mfccs,X_chroma,X_mel,X_contrast,X_tonnetz],Y_train, \n",
    "          validation_data = ([X_stft_test,X_mfccs_test,X_chroma_test,X_mel_test,X_contrast_test,X_tonnetz_test], Y_test), \n",
    "          epochs=200, batch_size=256, shuffle=True, callbacks=[early_stopping])\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate([X_stft_test,X_mfccs_test,X_chroma_test,X_mel_test,X_contrast_test,X_tonnetz_test], Y_test, verbose=0)\n",
    "print(\"Model Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
